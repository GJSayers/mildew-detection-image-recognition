{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling and Evaluation Notebook\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective:\n",
    " - Satisfy business requirement 2:\n",
    " - The client is interested in predicting if a cherry leaf is healthy or contains powdery mildew.\n",
    "\n",
    "### Inputs\n",
    "- inputs/cherry-leaves_dataset/cherry-leaves/test\n",
    "- inputs/cherry-leaves_dataset/cherry-leaves/train\n",
    "- inputs/cherry-leaves_dataset/cherry-leaves/validation\n",
    "\n",
    "### Outputs\n",
    "- Distribution plot of images in test, train and validatio sets\n",
    "- Image augmentation\n",
    "- Class indices to change prediction inferance in lables\n",
    "- ML model creation and training\n",
    "- Save trained model\n",
    "- Learning curve plot for model performance\n",
    "- Evaluate Model pickle file\n",
    "- Random image file prediction\n",
    "\n",
    "### Comments/Insights/Conclusions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r /workspace/mildew-detection-image-recognition/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory\n",
    "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory\n",
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/workspace/mildew-detection-image-recognition')\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Input Directories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set test, train, validation paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_dir = 'inputs/cherry-leaves_dataset/cherry-leaves'\n",
    "train_path = my_data_dir + '/train'\n",
    "val_path = my_data_dir + '/validation'\n",
    "test_path = my_data_dir + '/test'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v1'\n",
    "file_path =f'outputs/{version}'\n",
    "\n",
    "if 'outputs' in os.listdir(current_dir) and version in os.listdir(current_dir + '/outputs'):\n",
    "    print('Existing version already available create a new version')\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set label names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(train_path)\n",
    "print('Label for the images is', labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import saved image shape embedding\n",
    "import joblib\n",
    "version = 'v1'\n",
    "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
    "image_shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Number of Images in test, train and validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = pd.DataFrame([]) \n",
    "for folder in ['train', 'validation', 'test']:\n",
    "  for label in labels:\n",
    "    df_freq = df_freq.append(\n",
    "        pd.Series(data={'Set': folder,\n",
    "                        'Label': label,\n",
    "                        'Frequency':int(len(os.listdir(my_data_dir+'/'+ folder + '/' + label)))}\n",
    "                  ),\n",
    "                  ignore_index=True\n",
    "        )\n",
    "    \n",
    "    print(f\"* {folder} - {label}: {len(os.listdir(my_data_dir+'/'+ folder + '/' + label))} images\")\n",
    "\n",
    "print(\"\\n\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
    "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image data augmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our dataset only shows a limited number of images, we need to augment the images to increase the learning capacity of the ML model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ImageDataGenerator form Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we initialize the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_image_data = ImageDataGenerator(rotation_range=15,\n",
    "                                   width_shift_range=0.12, \n",
    "                                   height_shift_range=0.10,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest',\n",
    "                                   rescale=1./255\n",
    "                              )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment training image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20 # Set batch size\n",
    "train_set = augmented_image_data.flow_from_directory(train_path,\n",
    "                                              target_size=image_shape[:2],\n",
    "                                              color_mode='rgb',\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='binary',\n",
    "                                              shuffle=True\n",
    "                                              )\n",
    "\n",
    "train_set.class_indices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment validation image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
    "                                                          target_size=image_shape[:2],\n",
    "                                                          color_mode='rgb',\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          class_mode='binary',\n",
    "                                                          shuffle=False\n",
    "                                                          )\n",
    "\n",
    "validation_set.class_indices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment test image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
    "                                                    target_size=image_shape[:2],\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary',\n",
    "                                                    shuffle=False\n",
    "                                                    )\n",
    "\n",
    "test_set.class_indices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot augmented training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = train_set.next()\n",
    "    print(img.shape)   #  (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot augmented validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = validation_set.next()\n",
    "    print(img.shape)   #  (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot augmented test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = test_set.next()\n",
    "    print(img.shape)   \n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save class indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joblib.dump(value=train_set.class_indices ,\n",
    "            filename=f\"{file_path}/class_indices.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the ML Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "import keras_tuner\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Contsruct function to create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tf_model():\n",
    "    \n",
    "    # Convolution layers to filter the dominannt pixel values from the non-dominant, Maxpooling then reduces the image to only the dominant pixel values. The outcome being the complexity is reduced and the accuracy increased\n",
    "    # The activation types used here are relu (rectified linerar activation function) and sigmoid (logistic regression classification function) \n",
    "    # https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Convolution layers (filtering the dominant from non-dominant)\n",
    "    model.add(Conv2D(filters=32, kernel_size=(4,4), input_shape=image_shape, activation='relu',))\n",
    "    # Max pooling layers (reducing image to only the dominant pixel values)\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(4,4), input_shape=image_shape, activation='relu',))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(4,4), input_shape=image_shape, activation='relu',))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    # The Flatten layer transforms the matrix into a vector (a simgle list f all values)\n",
    "    model.add(Flatten())\n",
    "    # The Vector produced from the Flatten is fed to the Dense layer which peforms the mathematical calculation and provides the output \n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    \n",
    "    # Dropout layer \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "\n",
    "        loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy']\n",
    "                  )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build function to create Keras tuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tf_model(units, activation, dropout, lr):\n",
    "    model = keras.Sequential()\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=units, activation=activation))\n",
    "    if dropout:\n",
    "        model.add(Dropout(rate=0.25))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    units = hp.Int(\"units\", min_value=32, max_value=512, step=32)\n",
    "    activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    # call existing model-building code with the hyperparameter values.\n",
    "    model = build_tf_model(\n",
    "        units=units, activation=activation, dropout=dropout, lr=lr\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise the tuner"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set path for the search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_path = my_data_dir + '/tune'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialise the tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=5,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"tune_path\",\n",
    "    project_name=\"mildew-detection\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print a summary of the search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prepare the MNIST dataset to inform the tuning search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "(x, y), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x[:-10000]\n",
    "x_val = x[-10000:]\n",
    "y_train = y[:-10000]\n",
    "y_val = y[-10000:]\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
    "x_val = np.expand_dims(x_val, -1).astype(\"float32\") / 255.0\n",
    "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255.0\n",
    "\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Begin the search for the best hyperparameter config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train, y_train, epochs=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Query the search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "# Needed for `Sequential` without specified `input_shape`.\n",
    "best_model.build(input_shape=(None, 28, 28))\n",
    "best_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinstatiate the original model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tf_model():\n",
    "    \n",
    "    # Convolution layers to filter the dominannt pixel values from the non-dominant, Maxpooling then reduces the image to only the dominant pixel values. The outcome being the complexity is reduced and the accuracy increased\n",
    "    # The activation types used here are relu (rectified linerar activation function) and sigmoid (logistic regression classification function) \n",
    "    # https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Convolution layers (filtering the dominant from non-dominant)\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=image_shape, activation='relu',))\n",
    "    # Max pooling layers (reducing image to only the dominant pixel values)\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=image_shape, activation='relu',))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=image_shape, activation='relu',))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    # The Flatten layer transforms the matrix into a vector (a simgle list f all values)\n",
    "    model.add(Flatten())\n",
    "    # The Vector produced from the Flatten is fed to the Dense layer which peforms the mathematical calculation and provides the output \n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    \n",
    "    # Dropout layer \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "\n",
    "        loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy']\n",
    "                  )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  model = build_tf_model()\n",
    "model.fit(train_set,\n",
    "          epochs=25,\n",
    "          steps_per_epoch = len(train_set.classes) // batch_size,\n",
    "          validation_data=validation_set,\n",
    "          callbacks=[early_stop],\n",
    "          verbose=1\n",
    "          )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('outputs/v1/mildew_detection_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Learning curve of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "losses[['loss','val_loss']].plot(style='.-')\n",
    "plt.title(\"Loss\")\n",
    "plt.savefig(f'{file_path}/model_training_losses.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "losses[['accuracy','val_accuracy']].plot(style='.-')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.savefig(f'{file_path}/model_training_acc.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the output "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('outputs/v1/mildew_detection_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate the model using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the evaluation as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=evaluation ,\n",
    "            filename=f\"outputs/v1/model_evaluation.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prediction using a random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "pointer = 27\n",
    "label = labels[1] # select Healthy or Infected\n",
    "\n",
    "pil_image = image.load_img(test_path + '/'+ label + '/'+ os.listdir(test_path+'/'+ label)[pointer],\n",
    "                          target_size=image_shape, color_mode='rgb')\n",
    "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
    "pil_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert this image to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_arr_image = image.img_to_array(pil_image)\n",
    "my_arr_image = np.expand_dims(my_arr_image, axis=0)/255\n",
    "print(my_arr_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = model.predict(my_arr_image)[0,0]\n",
    "\n",
    "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
    "pred_cls =  target_map[pred_prob > 0.5]  \n",
    "\n",
    "if pred_cls == target_map[0]: pred_prob = 1 - pred_prob\n",
    "\n",
    "print(pred_prob)\n",
    "print(pred_cls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
